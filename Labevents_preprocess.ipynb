{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eadd992-8d88-46eb-8818-5f60fad79b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/fariham/mimic-iv-kg/data/processed/nodes/labitem_nodes.csv\n",
      "Rows: 1650\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:ID(LabItem)</th>\n",
       "      <th>:LABEL</th>\n",
       "      <th>itemid</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LABITEM_50801</td>\n",
       "      <td>LabItem</td>\n",
       "      <td>50801</td>\n",
       "      <td>Alveolar-arterial Gradient</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LABITEM_50802</td>\n",
       "      <td>LabItem</td>\n",
       "      <td>50802</td>\n",
       "      <td>Base Excess</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LABITEM_50803</td>\n",
       "      <td>LabItem</td>\n",
       "      <td>50803</td>\n",
       "      <td>Calculated Bicarbonate, Whole Blood</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LABITEM_50804</td>\n",
       "      <td>LabItem</td>\n",
       "      <td>50804</td>\n",
       "      <td>Calculated Total CO2</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LABITEM_50805</td>\n",
       "      <td>LabItem</td>\n",
       "      <td>50805</td>\n",
       "      <td>Carboxyhemoglobin</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    :ID(LabItem)   :LABEL  itemid                                label  fluid  \\\n",
       "0  LABITEM_50801  LabItem   50801           Alveolar-arterial Gradient  Blood   \n",
       "1  LABITEM_50802  LabItem   50802                          Base Excess  Blood   \n",
       "2  LABITEM_50803  LabItem   50803  Calculated Bicarbonate, Whole Blood  Blood   \n",
       "3  LABITEM_50804  LabItem   50804                 Calculated Total CO2  Blood   \n",
       "4  LABITEM_50805  LabItem   50805                    Carboxyhemoglobin  Blood   \n",
       "\n",
       "    category  \n",
       "0  Blood Gas  \n",
       "1  Blood Gas  \n",
       "2  Blood Gas  \n",
       "3  Blood Gas  \n",
       "4  Blood Gas  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Your paths\n",
    "DLABITEMS_PATH = \"/Users/fariham/Downloads/mimic-iv-3.1/hosp/d_labitems.csv\"\n",
    "\n",
    "# Output (change if you want)\n",
    "OUT_DIR = \"/Users/fariham/mimic-iv-kg/data/processed/nodes\"\n",
    "OUT_LABITEM_NODES = os.path.join(OUT_DIR, \"labitem_nodes.csv\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Read d_labitems (small file, safe to read all at once)\n",
    "d = pd.read_csv(DLABITEMS_PATH)\n",
    "\n",
    "# Keep common useful columns (only keep those that exist)\n",
    "keep = [c for c in [\"itemid\", \"label\", \"fluid\", \"category\", \"loinc_code\"] if c in d.columns]\n",
    "d = d[keep].drop_duplicates(subset=[\"itemid\"]).copy()\n",
    "\n",
    "# Admin-import IDs\n",
    "d[\":ID(LabItem)\"] = \"LABITEM_\" + d[\"itemid\"].astype(\"Int64\").astype(str)\n",
    "d[\":LABEL\"] = \"LabItem\"\n",
    "\n",
    "# Put ID + LABEL first, then the rest\n",
    "cols = [\":ID(LabItem)\", \":LABEL\"] + [c for c in keep]\n",
    "d = d[cols]\n",
    "\n",
    "# Write\n",
    "d.to_csv(OUT_LABITEM_NODES, index=False)\n",
    "\n",
    "print(\"Wrote:\", OUT_LABITEM_NODES)\n",
    "print(\"Rows:\", len(d))\n",
    "d.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91aa72e2-5250-4a23-b7bf-5cc4a578189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote chunk: 549,369   total written: 549,369\n",
      "wrote chunk: 523,601   total written: 1,072,970\n",
      "wrote chunk: 524,449   total written: 1,597,419\n",
      "wrote chunk: 539,805   total written: 2,137,224\n",
      "wrote chunk: 523,747   total written: 2,660,971\n",
      "wrote chunk: 529,558   total written: 3,190,529\n",
      "wrote chunk: 518,422   total written: 3,708,951\n",
      "wrote chunk: 543,296   total written: 4,252,247\n",
      "wrote chunk: 518,735   total written: 4,770,982\n",
      "wrote chunk: 540,073   total written: 5,311,055\n",
      "wrote chunk: 539,172   total written: 5,850,227\n",
      "wrote chunk: 533,894   total written: 6,384,121\n",
      "wrote chunk: 546,737   total written: 6,930,858\n",
      "wrote chunk: 556,190   total written: 7,487,048\n",
      "wrote chunk: 550,894   total written: 8,037,942\n",
      "wrote chunk: 513,526   total written: 8,551,468\n",
      "wrote chunk: 532,356   total written: 9,083,824\n",
      "wrote chunk: 526,588   total written: 9,610,412\n",
      "wrote chunk: 577,912   total written: 10,188,324\n",
      "wrote chunk: 529,140   total written: 10,717,464\n",
      "wrote chunk: 531,941   total written: 11,249,405\n",
      "wrote chunk: 547,472   total written: 11,796,877\n",
      "wrote chunk: 534,372   total written: 12,331,249\n",
      "wrote chunk: 554,680   total written: 12,885,929\n",
      "wrote chunk: 542,495   total written: 13,428,424\n",
      "wrote chunk: 547,772   total written: 13,976,196\n",
      "wrote chunk: 551,209   total written: 14,527,405\n",
      "wrote chunk: 518,256   total written: 15,045,661\n",
      "wrote chunk: 516,626   total written: 15,562,287\n",
      "wrote chunk: 519,924   total written: 16,082,211\n",
      "wrote chunk: 546,767   total written: 16,628,978\n",
      "wrote chunk: 538,613   total written: 17,167,591\n",
      "wrote chunk: 515,458   total written: 17,683,049\n",
      "wrote chunk: 540,183   total written: 18,223,232\n",
      "wrote chunk: 549,824   total written: 18,773,056\n",
      "wrote chunk: 517,730   total written: 19,290,786\n",
      "wrote chunk: 514,797   total written: 19,805,583\n",
      "wrote chunk: 527,807   total written: 20,333,390\n",
      "wrote chunk: 537,133   total written: 20,870,523\n",
      "wrote chunk: 541,082   total written: 21,411,605\n",
      "wrote chunk: 531,745   total written: 21,943,350\n",
      "wrote chunk: 545,611   total written: 22,488,961\n",
      "wrote chunk: 544,859   total written: 23,033,820\n",
      "wrote chunk: 530,756   total written: 23,564,576\n",
      "wrote chunk: 529,305   total written: 24,093,881\n",
      "wrote chunk: 544,065   total written: 24,637,946\n",
      "wrote chunk: 538,215   total written: 25,176,161\n",
      "wrote chunk: 517,887   total written: 25,694,048\n",
      "wrote chunk: 531,724   total written: 26,225,772\n",
      "wrote chunk: 530,995   total written: 26,756,767\n",
      "wrote chunk: 524,775   total written: 27,281,542\n",
      "wrote chunk: 540,223   total written: 27,821,765\n",
      "wrote chunk: 531,553   total written: 28,353,318\n",
      "wrote chunk: 530,775   total written: 28,884,093\n",
      "wrote chunk: 532,510   total written: 29,416,603\n",
      "wrote chunk: 535,640   total written: 29,952,243\n",
      "wrote chunk: 532,026   total written: 30,484,269\n",
      "wrote chunk: 549,193   total written: 31,033,462\n",
      "wrote chunk: 550,013   total written: 31,583,475\n",
      "wrote chunk: 550,529   total written: 32,134,004\n",
      "wrote chunk: 542,032   total written: 32,676,036\n",
      "wrote chunk: 562,867   total written: 33,238,903\n",
      "wrote chunk: 525,940   total written: 33,764,843\n",
      "wrote chunk: 542,748   total written: 34,307,591\n",
      "wrote chunk: 521,852   total written: 34,829,443\n",
      "wrote chunk: 529,370   total written: 35,358,813\n",
      "wrote chunk: 554,705   total written: 35,913,518\n",
      "wrote chunk: 528,705   total written: 36,442,223\n",
      "wrote chunk: 539,498   total written: 36,981,721\n",
      "wrote chunk: 521,474   total written: 37,503,195\n",
      "wrote chunk: 537,822   total written: 38,041,017\n",
      "wrote chunk: 506,174   total written: 38,547,191\n",
      "wrote chunk: 542,685   total written: 39,089,876\n",
      "wrote chunk: 508,997   total written: 39,598,873\n",
      "wrote chunk: 537,426   total written: 40,136,299\n",
      "wrote chunk: 546,432   total written: 40,682,731\n",
      "wrote chunk: 525,929   total written: 41,208,660\n",
      "wrote chunk: 525,733   total written: 41,734,393\n",
      "wrote chunk: 522,830   total written: 42,257,223\n",
      "wrote chunk: 522,384   total written: 42,779,607\n",
      "wrote chunk: 525,156   total written: 43,304,763\n",
      "wrote chunk: 524,424   total written: 43,829,187\n",
      "wrote chunk: 519,443   total written: 44,348,630\n",
      "wrote chunk: 530,188   total written: 44,878,818\n",
      "wrote chunk: 536,551   total written: 45,415,369\n",
      "wrote chunk: 543,617   total written: 45,958,986\n",
      "wrote chunk: 516,043   total written: 46,475,029\n",
      "wrote chunk: 532,465   total written: 47,007,494\n",
      "wrote chunk: 522,731   total written: 47,530,225\n",
      "wrote chunk: 541,535   total written: 48,071,760\n",
      "wrote chunk: 552,379   total written: 48,624,139\n",
      "wrote chunk: 541,851   total written: 49,165,990\n",
      "wrote chunk: 543,712   total written: 49,709,702\n",
      "wrote chunk: 531,253   total written: 50,240,955\n",
      "wrote chunk: 545,273   total written: 50,786,228\n",
      "wrote chunk: 523,276   total written: 51,309,504\n",
      "wrote chunk: 525,558   total written: 51,835,062\n",
      "wrote chunk: 560,105   total written: 52,395,167\n",
      "wrote chunk: 537,802   total written: 52,932,969\n",
      "wrote chunk: 520,043   total written: 53,453,012\n",
      "wrote chunk: 511,230   total written: 53,964,242\n",
      "wrote chunk: 511,902   total written: 54,476,144\n",
      "wrote chunk: 551,047   total written: 55,027,191\n",
      "wrote chunk: 532,338   total written: 55,559,529\n",
      "wrote chunk: 495,347   total written: 56,054,876\n",
      "wrote chunk: 526,604   total written: 56,581,480\n",
      "wrote chunk: 549,492   total written: 57,130,972\n",
      "wrote chunk: 550,896   total written: 57,681,868\n",
      "wrote chunk: 523,983   total written: 58,205,851\n",
      "wrote chunk: 518,590   total written: 58,724,441\n",
      "wrote chunk: 506,831   total written: 59,231,272\n",
      "wrote chunk: 541,771   total written: 59,773,043\n",
      "wrote chunk: 524,842   total written: 60,297,885\n",
      "wrote chunk: 537,087   total written: 60,834,972\n",
      "wrote chunk: 537,945   total written: 61,372,917\n",
      "wrote chunk: 540,358   total written: 61,913,275\n",
      "wrote chunk: 520,115   total written: 62,433,390\n",
      "wrote chunk: 556,553   total written: 62,989,943\n",
      "wrote chunk: 529,265   total written: 63,519,208\n",
      "wrote chunk: 548,500   total written: 64,067,708\n",
      "wrote chunk: 539,957   total written: 64,607,665\n",
      "wrote chunk: 539,384   total written: 65,147,049\n",
      "wrote chunk: 503,558   total written: 65,650,607\n",
      "wrote chunk: 510,490   total written: 66,161,097\n",
      "wrote chunk: 549,669   total written: 66,710,766\n",
      "wrote chunk: 549,101   total written: 67,259,867\n",
      "wrote chunk: 514,245   total written: 67,774,112\n",
      "wrote chunk: 530,026   total written: 68,304,138\n",
      "wrote chunk: 555,656   total written: 68,859,794\n",
      "wrote chunk: 557,178   total written: 69,416,972\n",
      "wrote chunk: 540,101   total written: 69,957,073\n",
      "wrote chunk: 530,044   total written: 70,487,117\n",
      "wrote chunk: 540,364   total written: 71,027,481\n",
      "wrote chunk: 516,709   total written: 71,544,190\n",
      "wrote chunk: 538,585   total written: 72,082,775\n",
      "wrote chunk: 545,130   total written: 72,627,905\n",
      "wrote chunk: 521,548   total written: 73,149,453\n",
      "wrote chunk: 527,239   total written: 73,676,692\n",
      "wrote chunk: 537,935   total written: 74,214,627\n",
      "wrote chunk: 510,093   total written: 74,724,720\n",
      "wrote chunk: 562,465   total written: 75,287,185\n",
      "wrote chunk: 521,579   total written: 75,808,764\n",
      "wrote chunk: 522,514   total written: 76,331,278\n",
      "wrote chunk: 543,318   total written: 76,874,596\n",
      "wrote chunk: 529,278   total written: 77,403,874\n",
      "wrote chunk: 532,027   total written: 77,935,901\n",
      "wrote chunk: 534,143   total written: 78,470,044\n",
      "wrote chunk: 556,516   total written: 79,026,560\n",
      "wrote chunk: 553,642   total written: 79,580,202\n",
      "wrote chunk: 539,512   total written: 80,119,714\n",
      "wrote chunk: 534,141   total written: 80,653,855\n",
      "wrote chunk: 520,798   total written: 81,174,653\n",
      "wrote chunk: 528,409   total written: 81,703,062\n",
      "wrote chunk: 549,432   total written: 82,252,494\n",
      "wrote chunk: 547,817   total written: 82,800,311\n",
      "wrote chunk: 529,104   total written: 83,329,415\n",
      "wrote chunk: 533,892   total written: 83,863,307\n",
      "wrote chunk: 540,349   total written: 84,403,656\n",
      "wrote chunk: 202,211   total written: 84,605,867\n",
      "DONE. Output: /Users/fariham/mimic-iv-kg/data/processed/relationships/admission_has_lab_rels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "LABEVENTS_PATH = \"/Users/fariham/Downloads/mimic-iv-3.1/hosp/labevents.csv\"\n",
    "\n",
    "OUT_DIR = \"/Users/fariham/mimic-iv-kg/data/processed/relationships\"\n",
    "OUT_LAB_RELS = os.path.join(OUT_DIR, \"admission_has_lab_rels.csv\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Only read columns we will use (big speedup)\n",
    "usecols = [\n",
    "    \"hadm_id\", \"itemid\",\n",
    "    \"labevent_id\", \"specimen_id\",\n",
    "    \"charttime\", \"storetime\",\n",
    "    \"value\", \"valuenum\", \"valueuom\",\n",
    "    \"ref_range_lower\", \"ref_range_upper\",\n",
    "    \"flag\", \"priority\"\n",
    "]\n",
    "# In extract is missing some columns, weâ€™ll detect available columns first\n",
    "sample = pd.read_csv(LABEVENTS_PATH, nrows=5)\n",
    "usecols = [c for c in usecols if c in sample.columns]\n",
    "\n",
    "chunksize = 1_000_000\n",
    "first = True\n",
    "rows_written = 0\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    LABEVENTS_PATH,\n",
    "    usecols=usecols,\n",
    "    chunksize=chunksize,\n",
    "    low_memory=False\n",
    "):\n",
    "    # Keep only rows that can create an edge\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"itemid\"]).copy()\n",
    "\n",
    "    # Match your admin-import node ID format (change if your Admission IDs differ)\n",
    "    chunk[\":START_ID(Admission)\"] = \"ADM_\" + chunk[\"hadm_id\"].astype(\"Int64\").astype(str)\n",
    "    chunk[\":END_ID(LabItem)\"] = \"LABITEM_\" + chunk[\"itemid\"].astype(\"Int64\").astype(str)\n",
    "    chunk[\":TYPE\"] = \"HAS_LAB\"\n",
    "\n",
    "    # ---- Type/clean numeric props (Neo4j admin import supports prop:type headers)\n",
    "    if \"valuenum\" in chunk.columns:\n",
    "        chunk[\"valuenum:float\"] = pd.to_numeric(chunk[\"valuenum\"], errors=\"coerce\")\n",
    "        chunk.drop(columns=[\"valuenum\"], inplace=True)\n",
    "\n",
    "    if \"ref_range_lower\" in chunk.columns:\n",
    "        chunk[\"ref_range_lower:float\"] = pd.to_numeric(chunk[\"ref_range_lower\"], errors=\"coerce\")\n",
    "        chunk.drop(columns=[\"ref_range_lower\"], inplace=True)\n",
    "\n",
    "    if \"ref_range_upper\" in chunk.columns:\n",
    "        chunk[\"ref_range_upper:float\"] = pd.to_numeric(chunk[\"ref_range_upper\"], errors=\"coerce\")\n",
    "        chunk.drop(columns=[\"ref_range_upper\"], inplace=True)\n",
    "\n",
    "    # ---- Keep times as strings (fast)\n",
    "    if \"charttime\" in chunk.columns:\n",
    "        chunk[\"charttime:string\"] = chunk[\"charttime\"].astype(str)\n",
    "        chunk.drop(columns=[\"charttime\"], inplace=True)\n",
    "\n",
    "    if \"storetime\" in chunk.columns:\n",
    "        chunk[\"storetime:string\"] = chunk[\"storetime\"].astype(str)\n",
    "        chunk.drop(columns=[\"storetime\"], inplace=True)\n",
    "\n",
    "    # ---- Rename text props to typed strings (optional but nice)\n",
    "    rename_map = {}\n",
    "    for c in [\"value\", \"valueuom\", \"flag\", \"priority\"]:\n",
    "        if c in chunk.columns:\n",
    "            rename_map[c] = f\"{c}:string\"\n",
    "    chunk.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # Final column order for relationship import\n",
    "    base = [\":START_ID(Admission)\", \":END_ID(LabItem)\", \":TYPE\"]\n",
    "    prop_cols = [c for c in chunk.columns if c not in base and c not in [\"hadm_id\", \"itemid\"]]\n",
    "    out = chunk[base + prop_cols]\n",
    "\n",
    "    out.to_csv(OUT_LAB_RELS, mode=\"w\" if first else \"a\", header=first, index=False)\n",
    "    first = False\n",
    "    rows_written += len(out)\n",
    "\n",
    "    # progress print every chunk\n",
    "    print(f\"wrote chunk: {len(out):,}   total written: {rows_written:,}\")\n",
    "\n",
    "print(\"DONE. Output:\", OUT_LAB_RELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c5d411-a663-4780-8121-ec69a9bd65bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook working directory (cwd):\n",
      "/Users/fariham/Downloads/mimic-iv-3.1\n",
      "\n",
      "Looking for labitem_nodes.csv and admission_has_lab_rels.csv under your home folder...\n",
      "\n",
      "/Users/fariham/mimic-iv-kg/data/processed/nodes/labitem_nodes.csv\n",
      "/Users/fariham/mimic-iv-kg/data/processed/relationships/admission_has_lab_rels.csv\n",
      "\n",
      "Total found: 2\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "\n",
    "print(\"Notebook working directory (cwd):\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(\"\\nLooking for labitem_nodes.csv and admission_has_lab_rels.csv under your home folder...\\n\")\n",
    "\n",
    "hits = []\n",
    "for pattern in [\n",
    "    \"/Users/fariham/**/labitem_nodes.csv\",\n",
    "    \"/Users/fariham/**/admission_has_lab_rels.csv\",\n",
    "]:\n",
    "    hits.extend(glob.glob(pattern, recursive=True))\n",
    "\n",
    "for h in hits:\n",
    "    print(h)\n",
    "\n",
    "print(\"\\nTotal found:\", len(hits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85034a-2167-4705-86d9-b2806edd53b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
